{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65385f6-a068-43ab-af09-69ddca7331c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.14.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (1.10.14)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tiktoken) (2022.10.31)\n",
      "Requirement already satisfied: httpcore in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai requests tiktoken numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e541890-6309-4aef-aa8e-c2a27f6d090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 21\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that assist about the Azure Security Policy.'}\n",
      "{'role': 'user', 'content': 'Write a condition to deny access if the field name does not match the patterns contoso?????? and contoso-???-##.'}\n",
      "{'role': 'assistant', 'content': 'If all of the field is name does not match contoso?????? and does not match contoso-???-##, then deny.'}\n",
      "\n",
      "Number of examples in validation set: 21\n",
      "First example in validation set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that assist about the Azure Security Policy.'}\n",
      "{'role': 'user', 'content': 'Design a rule that triggers denial if the name field deviates from both contoso?????? and contoso-???-## patterns.'}\n",
      "{'role': 'assistant', 'content': 'If all of the field is name does not match contoso?????? and does not match contoso-???-##, then deny.'}\n"
     ]
    }
   ],
   "source": [
    "# Run preliminary checks\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the training set\n",
    "with open('training_set.jsonl', 'r', encoding='utf-8') as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Load the validation set\n",
    "with open('validation_set.jsonl', 'r', encoding='utf-8') as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a59c4809-9658-4ed1-a919-fb5a2dcd2a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: training_set.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 85, 150\n",
      "mean / median: 108.14285714285714, 101.0\n",
      "p5 / p95: 87.0, 139.0\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 28, 59\n",
      "mean / median: 42.904761904761905, 43.0\n",
      "p5 / p95: 35.0, 52.0\n",
      "**************************************************\n",
      "Processing file: validation_set.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 85, 159\n",
      "mean / median: 106.57142857142857, 101.0\n",
      "p5 / p95: 86.0, 139.0\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 28, 59\n",
      "mean / median: 42.904761904761905, 43.0\n",
      "p5 / p95: 35.0, 52.0\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Validate token counts\n",
    "\n",
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\") # default encoding used by gpt-4, turbo, and text-embedding-ada-002 models\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = ['training_set.jsonl', 'validation_set.jsonl']\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd52e343-9e98-4d38-947b-27328ac2c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-2f5538adef3f41729111089d4fd79868\n",
      "Validation file ID: file-8cf6aa563aa44f6e9e7c4215853f6258\n"
     ]
    }
   ],
   "source": [
    "# Upload fine-tuning files\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version = \"2024-02-01\"  # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002\n",
    ")\n",
    "\n",
    "training_file_name = 'training_set.jsonl'\n",
    "validation_file_name = 'validation_set.jsonl'\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file = open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file = open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca643762-b4a4-463b-8afe-bc63e3ae4bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-7822acddcb504aadaa0fff72ccee5063\n",
      "Status: pending\n",
      "{\n",
      "  \"id\": \"ftjob-7822acddcb504aadaa0fff72ccee5063\",\n",
      "  \"created_at\": 1714752077,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": -1,\n",
      "    \"batch_size\": -1,\n",
      "    \"learning_rate_multiplier\": 1\n",
      "  },\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": null,\n",
      "  \"status\": \"pending\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"file-2f5538adef3f41729111089d4fd79868\",\n",
      "  \"validation_file\": \"file-8cf6aa563aa44f6e9e7c4215853f6258\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Submit fine-tuning training job\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file = training_file_id,\n",
    "    validation_file = validation_file_id,\n",
    "    model = \"gpt-35-turbo-0613\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters.\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b791b1d-6f11-444b-b3b6-08f08d685b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job ftjob-7822acddcb504aadaa0fff72ccee5063 finished with status: succeeded\n",
      "Checking other fine-tune jobs for this resource.\n",
      "Found 8 fine-tune jobs.\n"
     ]
    }
   ],
   "source": [
    "# Track training status\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print('Checking other fine-tune jobs for this resource.')\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(response.data)} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "143e0ae5-14da-4797-978a-e734f5b6ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"ftjob-7822acddcb504aadaa0fff72ccee5063\",\n",
      "  \"created_at\": 1714752077,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-7822acddcb504aadaa0fff72ccee5063\",\n",
      "  \"finished_at\": 1714754111,\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 4,\n",
      "    \"batch_size\": 1,\n",
      "    \"learning_rate_multiplier\": 1\n",
      "  },\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": [\n",
      "    \"file-ad472f0ed7384fd48192bd7de2519662\"\n",
      "  ],\n",
      "  \"status\": \"succeeded\",\n",
      "  \"trained_tokens\": 9084,\n",
      "  \"training_file\": \"file-2f5538adef3f41729111089d4fd79868\",\n",
      "  \"validation_file\": \"file-8cf6aa563aa44f6e9e7c4215853f6258\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response.model_dump_json(indent=2))\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f081886d-e4ea-4b6e-a658-9d692b9b1f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the field name does not match with \"contoso\", the effect will be \"deny\".\n"
     ]
    }
   ],
   "source": [
    "# Use the deployed customized model\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version = \"2024-02-01\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"Testfinetunev2\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"what will the effect if field name doesn't match with contoso? please give result in json format\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a336a-25a4-4b3e-839c-e3a219a4e7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a3b828-a4db-4f5e-a261-7c772ace152f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
